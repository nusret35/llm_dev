1 18.409 An Algorithmist’s Toolkit Nov. 19, 2009 
Lecture 20 
Lectur er: Jonathan Kelner 
Brief Review of Gram-Sc hmidt and Gauss’s Algorithm 
Our main task of this lecture is to show a polynomial time algorithm which approximately solves the Shortest 
Vector Problem (SVP) within a factor of 2O(n) for lattices of dimension n. It may seem that such an algorithm 
with exponential error bound is either obvious or useless. However, the algorithm of Lenstra, Lenstra and 
Lov´asz (LLL) is widely regarded as one of the most beautiful algorithms and is strong enough to give some 
extremely striking results in both theory and practice. 
Recall that given a basis b1,...,b n for a vector space (no lattices here yet), we can use the Gram-Sc hmidt 
process to construct an orthogonal basis b1∗,...,b∗ 
n such that b∗ 
1 = b1 and 
b∗ 
k = bk −[projection of bk onto span(b1,...,b k−1)] for all 2 ≤k ≤n (note that we do not normalize b∗ 
k). In 
particular, we have that for all k: 
• span(b1,...,b k) = span(b1∗,...,bk∗ ), 
• bk = /summationtextk
i=1 μkib∗ 
i , and 
• μkk =1. 
The above conditions can be rewritten as B = MB∗, where basis vectors are rows of B and B∗, and 
⎡ μ11 0 0 ... 0 ⎤ ⎡ 1 0 0 ... 0 ⎤ 
⎢ μ21 μ22 0 ... 0 ⎥ ⎢ μ21 1 0 ... 0 ⎥ 
M = ⎢ ⎢ ⎣ . . . ... ⎥ ⎥ ⎦ = ⎢ ⎢ ⎣ . . . . .. ⎥ ⎥ ⎦ . 
μn1 μn2 μn3 ... μnn μn1 μn2 μn3 ... 1 
Obviously det(M) = 1, and thus vol(B) = vol(B∗). However, the entries of M are not integers, and thus 
L(B) /negationslash∗). We have proved last time that = L(B
for any b∈L, ||b||≥min i{||b∗||}.i 
We’ll use this to prove useful bound for the shortest vector on lattice. 
Recall also that last time we saw the Gauss’s algorithm which solves SVP for d = 2. There are two key 
ingredien ts of the algorithm. The ﬁrst is a deﬁnition of “reduced basis” which characterizes the discrete 
version of bases being orthogonal: namely , 
a basis {u,v}for a 2-d lattices is said to be reduced,if |u|≤|v|and |u·v|≤ |u|2 .2 
The second is an eﬃcien t procedure that produces a reduced basis. The procedure consists of two stages: 
First is a Euclid-lik e process which subtracts a multiple of the shorter vector from the longer one to get a 
vector as short as possible. The second stage is, if the length ordering is broken, we swap the two vectors 
and repeat, otherwise (i.e., |u|≤|v|) the procedure ends. To make the above procedure obviously terminate 
in polynomial time, we change the termination criterion to be (1 −/epsilon1)|u|≤|v|. This only gives us a (1 −/epsilon1)­
approximation, but is good enough. The basic idea of LLL algorithm is to generalize Gauss’s algorithm to 
higher dimensions. 
20-1 2 LLL Algorithm 
2.1	 Reduced Basis 
In order to ﬁnd a short vector in the lattice, we would like to perform a discrete version of GS procedure. 
To this end, we need to formalize the notion of being orthogonal in lattice problems. One way to do this 
is to say that the result of our procedure is “almost orthogonalized” so that doing Gram-Sc hmidt does not 
change much. 
Deﬁnition 1 (Reduced Basis) Let {b1,...,b n} be a basis for a lattic e L and let M be its GS matrix 
deﬁne d in Section 1. {b1,...,b n} is a reduced basis if it meets the following two conditions: 
• Condition 1: all the non-diagonal entries of M satisfy |μik|≤ 1/2. 
• Condition 2: for each i, ||πSi bi||2 ≤ 4 ||πSi bi+1||2, wher e Si is the ortho gonal complement of (i.e., the 3 
subsp ace ortho gonal to) span(b1,...,b i−1), and πSi is the projection operator to Si. 
Remark The constan t 4/3 here is to guaran tee polynomial-time termination of the algorithm, but the 
choice of the exact value is somewhat arbitrary . In fact, any number in (1,4) will do. 
Remark Condition 2 is equivalent to ||b∗ + μi+1 ,ib∗ 
i ||2 ≥ 3 ||b∗ 
i ||2 and one may think it as requiring i+1	 4 
that the projections of any two successiv e basis vectors bi and bi+1 onto Si satisfy a gapped norm ordering 
condition, analogous to what we did in Gauss’s algorithm for 2D case. 
2.2	 The algorithm 
Given {b1,...,b n}, the LLL algorithm works as below. 
LLL Algorithm for SVP 
Repeat the following two steps until we have a reduced basis 
Step 1: Gauss Reduction 
Compute the GS matrix M
for i=1 to n
for k = i− 1to1
m← nearest integer to μik
bi ← bi − mb k
end 
end 
Step 2: Swapping 
if exists i s.t. ||πSi bi||2 > 4 ||πSi bi+1||2 
3 
then	 swap bi and bi+1
go to Step 1
Analysis of LLL Algorithm 
The LLL algorithm looks pretty intuitive, but it is not obvious at all that it converges in polynomial number 
of steps or gives a good answer to SVP. We’ll see that it indeed works. 
20-2 3 /productdisplay 3.1 LLL produces a short vector 
We ﬁrst show that reduced basis gives a short vector. 
n−1 
2 Claim 2 If b1,...,b n is a reduced basis, then ||b1|| ≤ 2 λ1(L). 
Pro of Note that 
4 ||b ∗ 
i ||2 = ||πSi bi||2 ≤ ||πSi bi+1||2 
3 
4 4 4 = ||bi∗ 
+1 + μi+1 ,ibi ∗ ||2 = ||bi∗ 
+1||2 + μi2
+1 ,i||bi ∗ ||2 
3 3 3 
4 1 ≤ ||b ∗ 
i+1||2 + ||bi ∗ ||2 ,3 3 
which gives ||bi∗ 
+1||2 ≥ 1 ||bi ∗||2 . By induction on i,wehave 2 
1 1 ||bi ∗ ||2 ≥ ||b1∗ ||2 = ||b1||2 .2i−1 2i−1 
Recall that ∀b ∈ L, ||b|| ≥ min i ||b∗||. Therefore λ1(L) ≥ min i ||b∗||, which combined with the inequalit y i	 i 
above yields 
||b1||2 ≤ min{2i−1||bi ∗ ||2}≤ 2n−1 min{||bi ∗ ||2}≤ 2n−1λ1(L)2 
i	 i 
as desired. 
3.2 Con vergence of LLL 
Now we show that the LLL algorithm terminates in polynomial time. Note that in each iteration of LLL, 
Step 1 takes polynomial time and Step 2 takes O(1) times. What we need to show is that we only need 
to repeat Step1and Step2ap olynomial number of times. To this end, we deﬁne a potential function as 
follows: n 
D(b1,...,b n)= ||bi ∗ ||n−i . 
i=1 
It is clear that Step 1 does not change D since we do not change the Gram-Sc hmidt basis. 
We are going to show that each iteration of Step 2 decreases D by a constan t factor. In Step 2, we swap i 
and i+ 1 only when ||b∗||2 >4/3||πSi bi+1||2 ≥ 4/3||b∗ ||2 . Therefore each swapping decreases D by a factor √ i	 i+1
of at least 2/ 3, as desired. 
It is left to show that D can be upper-and lower-bounded. Since ||b∗||≤||bi||, the initial value of D cani /producttextbe upper bounded by (max i ||bi||)n(n−1)/2 . On the other hand, we may rewrite D as n |det(Λ i)|, where i=1 
Λi is the lattice spanned by b1,...,b i. Since we assume that the lattice basis vectors are integer-v alued, so 
D is at least 1. 
In sum, the algorithm must terminate in log√ (max i ||bi||)n(n−1)/2 = poly(n) iterations. 2/ 3
4	Application of LLL–Lenstra’s Algorithm for Integer Program­
ming 
4.1 Applications of LLL 
LLL algorithm has many important applications in various ﬁelds of computer science. Here are a few (many 
taken from Regev’s notes): 
1. Solve integer programming in bounded dimension as we are going to see next. 
20-3 2. Factor polynomials over the integers or rationals. Note that this problem is harder than the same task 
but over reals, e.g. it needs to distinguish x2 −1 from x2 −2. 
3. Given an approximation of an algebraic number, ﬁnd its minimal polynomial.	 For example, given 
0.645751 outputs x2 +4x−3. 
4. Find integer relations among a set of numbers. A set of real numbers {x1,...,x n} is said to have an 
integer relation if there exists a set of integers {a1,...,a n} not identically zero such that a1x1 + ···+ 
anxn = 0. As an example, if we are given arctan(1) ,arctan(1 /5) and arctan(1 /239), we should output 
arctan(1) −4arctan(1 /5) + arctan(1 /239) = 0. How would you ﬁnd this just given these numbers as 
decimals? 
5. Appro ximate to SVP, CVP and some other lattice problems. 
6. Break a whole bunch of cryptosystems. For example, RSA with low public exponent and many knapsac k 
based cryptographic systems. 
7. Build real life algorithms for some NP-hard problems, e.g. subset sum problem. 
4.2 Integer Programming in Bounded Dimension 
4.2.1 Linear, Con vex and Integer Programming 
Consider the following feasibilit y version of the linear programming problem: 
•	Linear Programming (feasibilit y)
Given: An m×n matrix A and a vector b∈Rn
Goal: Find a point x∈Rn s.t. Ax≤b, or determine (with a certiﬁcate) that none exists
One can show that other versions, such as the optimization version, are equivalent to feasibilit y version. 
If we relax the searching regions from polytop es to convex bodies, we get convex programming. 
•	Convex Programming (feasibilit y)
Given: A separation oracle for a convex body K and a promise that
–	K is contained in a ball of singly exponential radius R 
– if K is non-empt y, it contains a ball of radius r which is at least 1/(singly exponential) 
Goal: Find a point x∈Rn that belongs to K, or determine (with a certiﬁcate) that none exists 
Integer programming is the same thing as above, except that we require the program to produce a point 
in Zn, not just Rn . Although linear programming and convex programming are known to be in P, integer 
programming is a well-kno wn NP-complete problem. 
4.2.2 Lenstra’s algorithm 
Theorem 3 (Lenstra) If our polytop e/convex body is in Rn for any constant n, then ther e exists a poly­
nomial time algorithm for inte ger programming. 
20-4 Remark. 
•	For linear programming (LP), the running time of the algorithm will grow exponentially in n, but 
polynomially in m (the number of constrains) and the number of bits in the inputs. 
•	For convex programming, the running time is polynomial in log(R/r). 
•	As before, we could also ask for maximum of c · x over all x ∈ K ∩ Zn, which is equivalent to the 
feasibility problem, as we can do a binary search on the whole range of c · x. 
The main idea of Lenstra’s algorithm is the following. The main diﬃculty of integer programming comes 
from the fact that K may not be well-rounded, therefore it could be exponentially large but still contain no 
integral point, as illustrated in the following ﬁgure: 
Figure 1: A not-well-rounded convex body 
Our ﬁrst step is thus to change the basis so that K is well-rounded, i.e., K contains a ball of radius 1 
and is contained in a ball of radius c(n) for some function that depends only on n. Such a transformation 
will sends Zn to some lattice L. Now our convex body is well-rounded but the basis of lattice L may be 
ill-conditioned, as shown in the following ﬁgure: 
Figure 2: A well-rounded convex body and an ill-conditioned lattice basis 
20-5 x2x1 + x2
x1
Figure by MIT OpenCourseWare.
Figure by MIT OpenCourseWare./productdisplay It turns out that the lattice points are still well-separated and we can remedy the lattice basis by a basis 
reduction procedure of LLL (i.e., discrete Gram-Sc hmidt). Finally we chop the lattice space up in some 
intelligen t way and search for lattice points in K. 
Note that in the ﬁrst step of Lenstra’s algorithm, what we need is an algorithmic version of Fritz John’s 
theorem. As we saw in the problem set, there is an eﬃcien t algorithm which, for any convex body K speciﬁed 
by a separation oracle, constructs an ellipsoid E such that 
E(P/prime) ⊆ K ⊆ O(n 3/2)E(P/prime). 
Next let T : Rn → Rn be the linear transformation such that E(P/prime) is transformed to B(P,1). NowKis 
sandwic hed between two reasonably-sized balls: 
B(P,1) ⊆ TK ⊆ B(P,R), 
where R = O(n3/2) is the radius of the outer ball. 
Let L = TZn with basis Te1,...,T en. Our goal is to ﬁnd a point (if it exists) in TK ∩ TZn = TK ∩ L. 
Our next step is to apply the basis reduction in LLL algorithm. We will need the following two lemmas in 
analyzing Lenstra’s algorithm. The proofs of the lemmas are left as exercises. 
Lemma 4 Let b1,...,b n be any basis for L with ||b1||2 ≤··· ≤||bn||2 . Then for every x ∈ Rn, ther e exists 
a lattic e point y such that 
1 ||x− y||2 ≤ (||b1||2 + ··· + ||bn||2)4 
1 ≤ n||bn||2 .4 
Lemma 5 For a reduced basis b1,...,b n ordered as above, 
n 
||bi|| ≤ 2n(n−1)/4det(L). 
i=1 
Conse quently, if we let H = span(b1,...,b n−1), then 
2−n(n−1)/4||bn|| ≤ dist(H,bn) ≤||bn||. 
√Let b1,...,b n be a reduced basis for L. Applying Lemma 4 gives us a point y ∈ L such that ||y− P|| ≤ 
1 n||bn||.2 
• case 1: y ∈ TK. We ﬁnd a point in TK ∩ L. 
• case 2: y/∈ TK, hence y/∈ B(P,1). Consequen tly, ||y− P|| ≥ 1 and ||bn|| ≥ √2. n 
This means that the length of bn is not much smaller than R. In the following we partition L along the 
sublattice “orthogonal” to bn and then apply this process recursiv ely. /uniontext Let L/prime be the lattice spanned by b1,...,b n−1 and let Li = L/prime + ibn for each i∈ Z. Clearly L = i∈Z Li. 
From Lemma 5 the distance between two adjacen t hyperplanes is at least 
dist(bn,span(b1,...,b n−1)) ≥ 2−n(n−1)/4||bn||
2 ≥√ 2−n(n−1)/4||bn|| = c1(n), n 
where c1(n) is some function that depends only on n. This implies that the convex body TK can not 
intersect with too many hyperplanes. That is 
|{i∈ Z : Li ∩ B(P,R) /negationslash= ∅}| ≤ 2R/c1(n)= c2(n) 
for some function c2(n) that depends only on n. Now we have reduced our original searching problem in 
n-dimensional space to c2(n) instances of searching problems in (n− 1)-dimensional space. Therefore we 
can apply this process recursiv ely and the total running time will be a polynomial in the input size times a 
function that depends only on n. 
20-6 MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.409 Topics in Theoretical Computer Science: An Algorithmist's Toolkit
Fall 2009 