� 
� 18.409 An Algorithmist’s Toolkit Decem ber 8, 2009 
Lecture 24 
Lecturer: Jonathan Kelner Scrib e: Dimiter Ostrev 
Multiplicativ e Weights 
In this lecture we will introduce Multiplicativ e Weights, a simple technique with many applications. We 
start with an example. 
Example Supp ose Mr. X wants to bet on football games but does not know much about football himself. 
Before each game, X can check the predictions of n experts. Is there an algorithm that allows Mr. X to 
perform well in the long run? 
Two potential ideas are: 
(1) For each game, bet according to what the majority of experts predict 
(2) Wait a few game s to see which of the experts get it right most of the time and then follow their advice 
These strategies work well in some cases but not in others: (1) fails when only a few experts make good 
predictions, and (2) fails when there is an expert that performs well for the ﬁrst few games and then never 
makes a correct prediction again. Instead, we will consider a combination of the two approac hes: for each 
game, we will consider the opinion of all experts, but each expert’s opinion will be weighted according to 
his past performance. More precisely , let wit denote the weight of expert i after t games, and consider the 
following algorithm: 
1. Set wi 0 = 1 for i =1, ..., n 
2. Make a prediction for game t based on a weighted majority of experts where expert i gets weight 
wit−1/ j wjt−1 
3. After game t update the weights as follows: if expert i’s prediction for game t was wrong then set 
t tw= (1 − �)w t−1; otherwise set w= w t−1 
i i ii 
For this algorithm, we have the following: 
Theorem Let mt
i denote the number of mistakes that expert i makes in the ﬁrst t games and mt denote 
the number of mistak es that Mr. X makes in the ﬁrst t games. Then for all i and t, 
2log(n) m t ≤ � + 2(1 + �)m t 
i 
and in particular, this holds for the i that minimizes mit . 
Proof Deﬁne Φk = i wik . If Mr. X makes a mistak e at game k, then a weighted majority of the experts 
must have made a wrong prediction for game k. The weights of all these experts drop by a factor of (1 − �) 
and so we have Φk ≤ (1 − �/2)Φk−1 . Then over the ﬁrst t games we have 
t tΦt ≤ (1 − � )m Φ0 = n(1 − � )m 
2 2
On the other hand we have wt = (1 − �)mit and so
i 
24-1 � 
� 
� t 
i Φt ≥ wit = (1 − �)m 
Therefore, 
t t 
i n(1 − 2)m ≥ (1 − �)m 
Rearranging this inequality gives 
log(n) log(1 − �) m t + m t
i ≤−log(1 − �/2) log(1 − �/2) 
This bound is slightly stronger than the one in the statemen t of the theorem. Using the inequalit ies 
�/2 ≤−log(1 − �/2) and � + �2 ≥−log(1 − �) converts it to the required form and completes the proof. 
Next, we will modify our algorithm to get rid of the factor of 2 on the right hand side of the bound above. 
Consider the following: 
1. Set wi 0 = 1 for i =1, ..., n 
2. To make a prediction for game t, do the following: for i =1, ...n, follow expert i’s prediction with 
probabilit y pt
i = wit−1/ j wjt−1 
3. After game t update the weights as follows: if expert i’s prediction for game t was wrong then set 
wt = (1 − �)w t−1 else set wt = w t−1 
i i ii 
For this algorithm, we have the following: 
Theorem Let mit denote the number of mistak es that expert i makes in the ﬁrst t games and let mt denote 
the random variable equal to the number of mistak es that Mr. X makes in the ﬁrst t games. Then for �< 1/2 
and for all i and t, 
E(m t) ≤ log
� (n) +(1+ �)mit 
and in particular, this holds for the i that minimizes mit . 
The proof of this Theorem is similar to before and we will omit it. Instead, we will introduce our most 
general version of the multiplicativ e weights algorithm. In the example above, we had only two possibilities 
for the relation between event outcomes and expert predictions: the outcome of game t either matc hed expert 
i’s prediction or it did not. Our measure of performance for individual experts and for the algorithm as a 
whole was simply counting wrong predictions. We want to generalize the algorithm to allow for an arbitrary 
set P of possible outcomes to events. In this setting, we will measure the performance of the algorithm as 
follows: we will say that at each step, following expert i’s prediction when the true outcome is j incurs a 
penalt y of M(i, j). More precisely , we have the following: 
0. The input of the algorithm consists of: a set P of possible outcomes to events. For i =1, ...n and for 
j ∈ P a number M(i, j) from the interval [−l, ρ]. We will refer to ρ as the width; we will also have the 
restriction l<ρ. 
1. Set wi 0 = 1 for i =1, ..., n 
2. To make a prediction for event t, do the following: for i =1, ...n, follow expert i’s prediction with 
probabilit y pt
i = wit−1/ j wjt−1 
24-2 � 3. Let jt denote the outcome of event t. Update the weights as follows: 
w t−1(1 − �)M(i,jt)/ρ if M(i, jt) ≥ 0 wit = { wii
t−1(1 + �)−M (i,jt)/ρ if M(i, jt) < 0 
A similar analysis to before gives: 
Theorem Let Dt denote the probabilit y distribution {p1t ,...,pnt } with which we pick experts to make a 
prediction for event t. Let M (Dt,jt) denote the expected value of our penalt y when following the distribution 
Dt for event t and when the actual outcome is jt . Then for � ≤ 1/2 and for all T and i, 
T� ρlog(n) � � 
M(Dt,jt) ≤ + (1 + �) M(i, jt) + (1 − �) M(i, jt) 
t=1 t:M(i,jt )≥0 t:M(i,jt)<0 
Corollary For any δ, for � ≤ min(1/2, δ/4ρ), for T = 16ρ2log(n)/δ2 rounds and for all i, the average 
penalt y we get per round obeys: 
�T �TM(Dt,jt) M(i, jt)t=1 t=1≤ δ + T T 
and in particular our average penalt y per round is at most δ bigger than the average penalt y of the best 
expert. 
Applications of Multiplicativ e Weights 
Our ﬁrst application of the Multiplicativ e Weights algorithm will be to zero-sum games. In a zero-sum game, 
we have a row player, R, and a column player, C. If R plays strategy i and C plays strategy j, then R pays 
C the amoun t M(i, j). Players can also play mixed strategies, i.e. probabilit y distributions over the sets of 
pure strategies. We will extend our payoﬀ notation so that M(D, P ) denotes the expected amoun t that R 
pays C when R plays the mixed strategy D and C plays the mixed strategy R. Recall that von Neumann’s 
Minimax Theorem states that 
minD maxj M(D, j)= maxP miniM (i, P ) 
We will denote the above quantity by λ; it is known as the value of the game. 
We are now ready to state the zero-sum game problem : given the sets of strategies for R and C and the 
payoﬀs M(i, j), estimate the value of the game λ. Our approac h will be to associate elemen ts of the curren t 
problem to appropriately chosen elemen ts of the Multiplicativ e Weights algorithm, then directly apply what 
we already know about Multiplicativ e Weights to conclude that we do indeed get a good appro ximation to 
λ in a reasonable amoun t of time. The details of the argumen t will be presented next lecture. 
24-3 MIT OpenCourseWare
http://ocw.mit.edu 
For information about citing these materials or our Terms of Use, visit: http://ocw.mit.edu/terms. 18.409 Topics in Theoretical Computer Science: An Algorithmist's Toolkit
Fall 2009 