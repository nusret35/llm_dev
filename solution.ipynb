{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from summarization_pipeline.pdf_section_extractor import extract_pdf_and_divide_sections\n",
    "from summarization_pipeline.extractor import Extractor\n",
    "from summarization_pipeline.image_processing import extract_image_title_pairs, extract_titles_from_page, convert_response_to_list, get_important_image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'article_parser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Option 1: Getting and preprocessing PDF input\u001b[39;00m\n\u001b[1;32m      3\u001b[0m business_pdf1_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/selinceydeli/Desktop/AIResearch/business-article-inputs/buss_article.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m sections_dict \u001b[38;5;241m=\u001b[39m \u001b[43mextract_pdf_and_divide_sections\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbusiness_pdf1_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/AIResearch/llm_dev/summarization_pipeline/pdf_section_extractor.py:90\u001b[0m, in \u001b[0;36mextract_pdf_and_divide_sections\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_pdf_and_divide_sections\u001b[39m(path):\n\u001b[1;32m     89\u001b[0m     extracted_text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(path)\n\u001b[0;32m---> 90\u001b[0m     parsed_sections \u001b[38;5;241m=\u001b[39m \u001b[43marticle_parser\u001b[49m\u001b[38;5;241m.\u001b[39mdivide_article_into_sections(extracted_text)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_sections\n",
      "\u001b[0;31mNameError\u001b[0m: name 'article_parser' is not defined"
     ]
    }
   ],
   "source": [
    "# Option 1: Getting and preprocessing PDF input\n",
    "\n",
    "business_pdf1_path = \"/Users/selinceydeli/Desktop/AIResearch/business-article-inputs/buss_article.pdf\"\n",
    "sections_dict = extract_pdf_and_divide_sections(business_pdf1_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting section texts of important sections \n",
    "\n",
    "abstract = sections_dict.get('abstract', \"\")\n",
    "\n",
    "critical_sections = [\"introduction\", \"conclusion\", \"discussion\", \"methodology\"]\n",
    "\n",
    "critical_section_information = {}\n",
    "for section_name in critical_sections:\n",
    "  critical_section_information[section_name] = sections_dict.get(section_name, \"\")\n",
    "\n",
    "\"\"\"\n",
    "If at least two of the sections among \"conclusion\", \"discussion\", and \"outcomes\" are missing, \n",
    "then take the last four sections (we keep each subsection seperately in the current formulation of sections_dict) \n",
    "of the article (excluding keywords, acknowledgments, and references sections)\n",
    "\"\"\"\n",
    "check_for_absence = \"\"\n",
    "critical_section_list = list(critical_section_information.items())\n",
    "for section_name, section_text in critical_section_list[-3:]:\n",
    "    if section_text == \"\": check_for_absence += '0'\n",
    "\n",
    "if len(check_for_absence) >= 2:\n",
    "    accepted = 0\n",
    "    unwanted_sections = [\"keywords\", \"acknowledgments\", \"references\"]\n",
    "    sections_list = list(sections_dict.items())\n",
    "    for section_name, section_text in sections_list[::-1]: # Reverse iteration of the sections_list\n",
    "        section_name = section_name.lower()\n",
    "        section_text = sections_dict.get(section_name, \"\")\n",
    "        if section_name not in unwanted_sections and section_text != \"\":\n",
    "            critical_section_information[section_name] = section_text\n",
    "            accepted += 1\n",
    "            if accepted >= 4:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarizing important sections\n",
    "    \n",
    "summarized_sections = {}\n",
    "for section_name, section_text in critical_section_information.items():\n",
    "    if section_text != \"\" and section_name != \"introduction\" and section_name != \"managerial implications\": \n",
    "        summary = Extractor.summarize(section_name, section_text)\n",
    "        summarized_sections[section_name] = summary\n",
    "        print(\"Summary of \" + section_name + \": \\n\" + summary)\n",
    "    else : summarized_sections[section_name] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enriching the abstract\n",
    "\n",
    "def create_section_input(summarized_sections):\n",
    "    # Initialize an empty string to store the formatted output\n",
    "    section_input = \"\"\n",
    "\n",
    "    # Iterate over each key-value pair in the dictionary\n",
    "    for key, value in summarized_sections.items():\n",
    "        # Append the key and value to the string with the specified format\n",
    "        section_input += f\"{key}: {value} \\n\"\n",
    "\n",
    "    return section_input\n",
    "\n",
    "section_input = create_section_input(summarized_sections)\n",
    "enriched_abstract = Extractor.enrich_abstract(section_input, abstract)\n",
    "print(enriched_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Extracting insights from the article using the summarized sections\n",
    "\n",
    "insights = Extractor.extract_insights(section_input)\n",
    "print(\"Extracted insights:\\n\" + insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Extracting insights from the article using the enriched abstract\n",
    "\n",
    "insights = Extractor.extract_insights(enriched_abstract)\n",
    "print(\"Extracted insights:\\n\" + insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a meaningful title to be presented as the chat title in the interface\n",
    "\n",
    "title = Extractor.generate_title(insights)\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the most important figures/tables of the article\n",
    "\n",
    "import fitz\n",
    "\n",
    "# Open the file\n",
    "pdf_file = fitz.open(business_pdf1_path)\n",
    "titles = []\n",
    "image_title_pairs = {}\n",
    "# Iterate over PDF pages\n",
    "for page_index in range(len(pdf_file)):\n",
    "    page = pdf_file[page_index]\n",
    "    page_image_title_pairs = extract_image_title_pairs(page,page_index)\n",
    "    page_image_titles = extract_titles_from_page(page)\n",
    "    image_title_pairs.update(page_image_title_pairs)\n",
    "    for title in page_image_titles:\n",
    "        title += \" (Page:\" + str(page_index+1) + \")\"\n",
    "        print(title)\n",
    "        titles.append(title)\n",
    "\n",
    "pdf_file.close()\n",
    "\n",
    "image_titles = \"\"\n",
    "for title in titles:\n",
    "    image_titles += title + \"\\n\"\n",
    "    \n",
    "important_images = Extractor.choose_images(insights, image_titles)\n",
    "print(important_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the fetched figures/tables that match the selected images\n",
    "\n",
    "important_images_list = convert_response_to_list(important_images)\n",
    "\n",
    "# Check whether the important image is extracted\n",
    "found_images = get_important_image_paths(image_title_pairs, important_images_list)\n",
    "print(found_images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
